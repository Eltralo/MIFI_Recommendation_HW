{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24e0997e",
   "metadata": {},
   "source": [
    "### Выполнила: Ковалева Екатерина Сергеевна  НИЯУ МИФИ группа М24-525"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec2f0fc",
   "metadata": {},
   "source": [
    "## Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6b41139b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split as sklearn_train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from surprise import Reader, Dataset, SVD, accuracy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c7affa",
   "metadata": {},
   "source": [
    "## Сид и девайс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5f2e6b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "50dd7308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Используется устройство: cpu\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Используется устройство: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a3a646",
   "metadata": {},
   "source": [
    "## Небольшая предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "02245709",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet('/home/administrator/Desktop/IDE/Recomendation/data_advanced.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0fbe8cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tags_to_string(tags):\n",
    "    if isinstance(tags, np.ndarray):\n",
    "        return ' '.join(tags.astype(str))\n",
    "    elif pd.isna(tags):\n",
    "        return ''\n",
    "    else:\n",
    "        return str(tags)\n",
    "\n",
    "data['tags_list_str'] = data['tags_list'].apply(tags_to_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "71d23722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Маппинг ID → индексы\n",
    "user_ids = data['user_id'].unique()\n",
    "book_ids = data['book_id'].unique()\n",
    "USER_COUNT = len(user_ids)\n",
    "BOOK_COUNT = len(book_ids)\n",
    "\n",
    "user_to_index = {uid: i for i, uid in enumerate(user_ids)}\n",
    "book_to_index = {bid: i for i, bid in enumerate(book_ids)}\n",
    "\n",
    "data['user_index'] = data['user_id'].map(user_to_index)\n",
    "data['book_index'] = data['book_id'].map(book_to_index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd5ec3c",
   "metadata": {},
   "source": [
    "## Разделение на треин и тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a178f17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 4,781,183, Test: 1,195,296\n"
     ]
    }
   ],
   "source": [
    "train, test = sklearn_train_test_split(data, test_size=0.2, stratify=(data['rating'] >= 3.5), random_state=42)\n",
    "all_items = data['book_id'].unique()\n",
    "user_seen_items = train.groupby('user_id')['book_id'].agg(set).to_dict()\n",
    "print(f\"Train: {len(train):,}, Test: {len(test):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9bf1ad",
   "metadata": {},
   "source": [
    "## Полезные функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e0b9de82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_metrics(recommender, test_data, user_seen_items_dict, all_items, k=10):\n",
    "    test_user_items = test_data.groupby('user_id')['book_id'].agg(list).to_dict()\n",
    "    precision_sum = recall_sum = ndcg_sum = 0\n",
    "    users_evaluated = 0\n",
    "\n",
    "    for user_id, true_items in tqdm(test_user_items.items(), desc=recommender.__class__.__name__):\n",
    "        if not true_items:\n",
    "            continue\n",
    "        user_history = user_seen_items_dict.get(user_id, set())\n",
    "        recs = recommender.recommend(user_id, user_history, k=k)\n",
    "        if not recs:\n",
    "            continue\n",
    "\n",
    "        users_evaluated += 1\n",
    "        rec_set = set(recs)\n",
    "        true_set = set(true_items)\n",
    "        hits = rec_set & true_set\n",
    "\n",
    "        precision_sum += len(hits) / len(recs)\n",
    "        recall_sum += len(hits) / len(true_items)\n",
    "\n",
    "        relevance = [1 if item in true_set else 0 for item in recs]\n",
    "        dcg = sum(r / np.log2(i + 2) for i, r in enumerate(relevance))\n",
    "        ideal = sorted(relevance, reverse=True)\n",
    "        idcg = sum(r / np.log2(i + 2) for i, r in enumerate(ideal))\n",
    "        ndcg_sum += dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "    if users_evaluated == 0:\n",
    "        return {'precision@10': 0, 'recall@10': 0, 'ndcg@10': 0}\n",
    "    return {\n",
    "        'precision@10': precision_sum / users_evaluated,\n",
    "        'recall@10': recall_sum / users_evaluated,\n",
    "        'ndcg@10': ndcg_sum / users_evaluated\n",
    "    }\n",
    "\n",
    "# Сегментация пользователей\n",
    "user_ratings_count = train.groupby('user_id')['book_id'].count().to_dict()\n",
    "\n",
    "def get_user_segment(user_id):\n",
    "    n = user_ratings_count.get(user_id, 0)\n",
    "    if n <= 0:\n",
    "        return \"cold\"\n",
    "    elif n <= 10:\n",
    "        return \"warm\"\n",
    "    else:\n",
    "        return \"active\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "44f42cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diversity_rerank(recommendations, data, k=10, diversity_penalty=0.3):\n",
    "    \"\"\"\n",
    "    Повышает разнообразие рекомендаций за счёт штрафа за общие теги.\n",
    "    \n",
    "    Параметры:\n",
    "        recommendations: список (book_id, score)\n",
    "        data: датафрейм с колонкой 'tags_list_str'\n",
    "        k: итоговое число рекомендаций\n",
    "        diversity_penalty: сила штрафа (0.0 = нет штрафа, 1.0 = полное подавление дублей)\n",
    "    \"\"\"\n",
    "    if not recommendations:\n",
    "        return []\n",
    "    \n",
    "    # Получаем теги для всех рекомендуемых книг\n",
    "    book_tags = {}\n",
    "    for book_id, _ in recommendations:\n",
    "        tags_str = data[data['book_id'] == book_id]['tags_list_str'].values\n",
    "        if len(tags_str) > 0:\n",
    "            book_tags[book_id] = set(tags_str[0].split())\n",
    "        else:\n",
    "            book_tags[book_id] = set()\n",
    "    \n",
    "    # Re-ranking\n",
    "    selected = []\n",
    "    remaining = recommendations.copy()\n",
    "    \n",
    "    while len(selected) < k and remaining:\n",
    "        # Выбираем книгу с максимальным (score - штраф)\n",
    "        best_idx = -1\n",
    "        best_score = -1\n",
    "        \n",
    "        for i, (book_id, score) in enumerate(remaining):\n",
    "            # Считаем штраф: чем больше общих тегов с уже выбранными — тем выше штраф\n",
    "            penalty = 0.0\n",
    "            if selected:\n",
    "                current_tags = book_tags[book_id]\n",
    "                overlap = 0\n",
    "                for sel_id in selected:\n",
    "                    overlap += len(current_tags & book_tags[sel_id])\n",
    "                penalty = diversity_penalty * (overlap / len(current_tags) if current_tags else 0)\n",
    "            \n",
    "            adjusted_score = score - penalty\n",
    "            if adjusted_score > best_score:\n",
    "                best_score = adjusted_score\n",
    "                best_idx = i\n",
    "        \n",
    "        # Добавляем лучшую книгу\n",
    "        selected_book = remaining.pop(best_idx)\n",
    "        selected.append(selected_book)\n",
    "    \n",
    "    return selected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a4d27a",
   "metadata": {},
   "source": [
    "# Модели для гибридной системы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414f687e",
   "metadata": {},
   "source": [
    "*Сравнительные метрики в конце нотубука*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a58e9c",
   "metadata": {},
   "source": [
    "## 1.Item-Based CF "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0bdaf4",
   "metadata": {},
   "source": [
    "*Создание user-item матрицы*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27724d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_train = train[['user_id', 'book_id', 'rating']].copy()\n",
    "user_item_matrix = ratings_train.pivot_table(index='user_id', columns='book_id', values='rating')\n",
    "user_item_matrix.fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b36faf",
   "metadata": {},
   "source": [
    "*Расчёт схожести между книгами*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "51346365",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_similarity = cosine_similarity(user_item_matrix.T)\n",
    "item_sim_df = pd.DataFrame(\n",
    "    item_similarity,\n",
    "    index=user_item_matrix.columns,\n",
    "    columns=user_item_matrix.columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd2d4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Создание user-item матрицы для Item-Based CF...\n",
      "Расчёт схожести между книгами...\n",
      "✅ Item-Based CF готова.\n"
     ]
    }
   ],
   "source": [
    "class ItemBasedRecommender:\n",
    "    def __init__(self, item_sim_df):\n",
    "        self.item_sim_df = item_sim_df\n",
    "\n",
    "    def recommend(self, user_id, user_seen_books, k=10):\n",
    "        if not user_seen_books:\n",
    "            return []\n",
    "        seen_in_catalog = [bid for bid in user_seen_books if bid in self.item_sim_df.index]\n",
    "        if not seen_in_catalog:\n",
    "            return []\n",
    "        similarity_scores = pd.Series(dtype='float64')\n",
    "        for book_id in seen_in_catalog:\n",
    "            sim_scores = self.item_sim_df[book_id]\n",
    "            similarity_scores = similarity_scores.add(sim_scores, fill_value=0)\n",
    "        similarity_scores = similarity_scores.drop(seen_in_catalog, errors='ignore')\n",
    "        top_books = similarity_scores.nlargest(k)\n",
    "        return top_books.index.tolist()\n",
    "\n",
    "item_model = ItemBasedRecommender(item_sim_df)\n",
    "print(\"Item-Based CF готова.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7e5755",
   "metadata": {},
   "source": [
    "## 2. Popularity модель (для cold-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c84d5ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Popularity модель готова.\n"
     ]
    }
   ],
   "source": [
    "class PopularityRecommender:\n",
    "    def __init__(self, popular_books):\n",
    "        self.popular_books = popular_books\n",
    "\n",
    "    def recommend(self, user_id, user_seen_books, k=10):\n",
    "        seen_set = set(user_seen_books)\n",
    "        recs = [b for b in self.popular_books if b not in seen_set]\n",
    "        return recs[:k]\n",
    "\n",
    "pop_model = PopularityRecommender(train['book_id'].value_counts().index.tolist())\n",
    "print(\"Popularity модель готова.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187b05ed",
   "metadata": {},
   "source": [
    "## 3. SVD модель\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1d889469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x7f9cc43d40e0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import Dataset, Reader, SVD\n",
    "train_surprise = train[['user_id', 'book_id', 'rating']].copy()\n",
    "train_surprise['user_id'] = train_surprise['user_id'].astype(str)\n",
    "train_surprise['book_id'] = train_surprise['book_id'].astype(str)\n",
    "\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "dataset = Dataset.load_from_df(train_surprise, reader)\n",
    "trainset = dataset.build_full_trainset()\n",
    "\n",
    "svd_algo = SVD(n_factors=50, n_epochs=20, random_state=42)\n",
    "svd_algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1e92017e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD модель готова.\n"
     ]
    }
   ],
   "source": [
    "class SVDRecommender:\n",
    "    def __init__(self, svd_model, train_data, k_candidates=2000):\n",
    "        self.svd_model = svd_model\n",
    "        self.popular_books = train_data['book_id'].value_counts().index.tolist()[:k_candidates]\n",
    "        self.known_users = set(train_data['user_id'])\n",
    "\n",
    "    def recommend(self, user_id, user_seen_books, k=10):\n",
    "        if user_id not in self.known_users:\n",
    "            seen_set = set(user_seen_books)\n",
    "            return [b for b in self.popular_books if b not in seen_set][:k]\n",
    "        seen_set = set(user_seen_books)\n",
    "        books_to_predict = [b for b in self.popular_books if b not in seen_set]\n",
    "        if not books_to_predict:\n",
    "            return []\n",
    "        testset = [[str(user_id), str(b), 4.0] for b in books_to_predict]\n",
    "        predictions = self.svd_model.test(testset)\n",
    "        predictions.sort(key=lambda x: x.est, reverse=True)\n",
    "        return [int(pred.iid) for pred in predictions[:k]]\n",
    "\n",
    "svd_model = SVDRecommender(svd_algo, train)\n",
    "print(\"SVD модель готова.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78be074",
   "metadata": {},
   "source": [
    "## 4. Two-Tower модель "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8945826f",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_FEATURES = ['user_avg_rating', 'user_ratings_count', 'rating_deviation_user']\n",
    "ITEM_FEATURES = ['weighted_rating', 'rating_std_dev']\n",
    "\n",
    "train_sample = train.sample(n=min(100000, len(train)), random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad2a23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Two-Tower модель готова.\n"
     ]
    }
   ],
   "source": [
    "class RecDataset(Dataset):\n",
    "    def __init__(self, df, user_features, item_features):\n",
    "        self.df = df\n",
    "        self.user_idx = torch.LongTensor(df['user_index'].values)\n",
    "        self.book_idx = torch.LongTensor(df['book_index'].values)\n",
    "        self.user_feat = self._normalize(df[user_features])\n",
    "        self.item_feat = self._normalize(df[item_features])\n",
    "        self.labels = torch.FloatTensor((df['rating'] >= 3.5).values)\n",
    "    \n",
    "    def _normalize(self, df_feat):\n",
    "        df = df_feat.copy()\n",
    "        for col in df.columns:\n",
    "            min_v, max_v = df[col].min(), df[col].max()\n",
    "            df[col] = (df[col] - min_v) / (max_v - min_v) if max_v > min_v else 0.5\n",
    "        return torch.FloatTensor(df.values)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.user_idx[idx], self.book_idx[idx], self.user_feat[idx], self.item_feat[idx], self.labels[idx]\n",
    "\n",
    "class TwoTowerModel(nn.Module):\n",
    "    def __init__(self, n_users, n_books, emb_dim, u_feat_dim, i_feat_dim):\n",
    "        super().__init__()\n",
    "        self.u_emb = nn.Embedding(n_users, emb_dim)\n",
    "        self.i_emb = nn.Embedding(n_books, emb_dim)\n",
    "        self.u_net = nn.Sequential(nn.Linear(emb_dim + u_feat_dim, 32), nn.ReLU(), nn.Linear(32, emb_dim))\n",
    "        self.i_net = nn.Sequential(nn.Linear(emb_dim + i_feat_dim, 32), nn.ReLU(), nn.Linear(32, emb_dim))\n",
    "    \n",
    "    def forward(self, u_idx, i_idx, u_feat, i_feat):\n",
    "        u_vec = self.u_net(torch.cat([self.u_emb(u_idx), u_feat], dim=1))\n",
    "        i_vec = self.i_net(torch.cat([self.i_emb(i_idx), i_feat], dim=1))\n",
    "        return (u_vec * i_vec).sum(dim=1).unsqueeze(1)\n",
    "\n",
    "train_ds = RecDataset(train_sample, USER_FEATURES, ITEM_FEATURES)\n",
    "train_loader = DataLoader(train_ds, batch_size=512, shuffle=True)\n",
    "\n",
    "model = TwoTowerModel(USER_COUNT, BOOK_COUNT, 16, len(USER_FEATURES), len(ITEM_FEATURES)).to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "for epoch in range(2):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_idx, (u_idx, b_idx, u_feat, i_feat, labels) in enumerate(train_loader):\n",
    "        u_idx, b_idx, u_feat, i_feat, labels = (\n",
    "            u_idx.to(DEVICE), b_idx.to(DEVICE), u_feat.to(DEVICE), i_feat.to(DEVICE), labels.to(DEVICE).unsqueeze(1)\n",
    "        )\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(model(u_idx, b_idx, u_feat, i_feat), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "model.eval()\n",
    "all_book_idx = torch.arange(BOOK_COUNT).to(DEVICE)\n",
    "with torch.no_grad():\n",
    "    dummy_item_feat = torch.zeros(BOOK_COUNT, len(ITEM_FEATURES)).to(DEVICE)\n",
    "    item_embeddings = model.i_net(torch.cat([model.i_emb(all_book_idx), dummy_item_feat], dim=1)).cpu().numpy()\n",
    "\n",
    "class TwoTowerRecommender:\n",
    "    def __init__(self, model, item_embeddings, user_to_index, book_to_index, idx_to_book_id):\n",
    "        self.model = model.eval()\n",
    "        self.item_embeddings = item_embeddings\n",
    "        self.user_to_index = user_to_index\n",
    "        self.book_to_index = book_to_index\n",
    "        self.idx_to_book_id = idx_to_book_id\n",
    "\n",
    "    def recommend(self, user_id, user_seen_books, k=10):\n",
    "        if user_id not in self.user_to_index:\n",
    "            return []\n",
    "        user_idx = self.user_to_index[user_id]\n",
    "        user_idx_tensor = torch.tensor([user_idx], dtype=torch.long).to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            dummy_user_feat = torch.zeros(1, len(USER_FEATURES)).to(DEVICE)\n",
    "            user_emb = self.model.u_net(torch.cat([self.model.u_emb(user_idx_tensor), dummy_user_feat], dim=1)).cpu().numpy().flatten()\n",
    "        scores = self.item_embeddings.dot(user_emb)\n",
    "        ranked_indices = np.argsort(scores)[::-1]\n",
    "        recs = []\n",
    "        seen_set = set(user_seen_books)\n",
    "        for idx in ranked_indices:\n",
    "            book_id = self.idx_to_book_id.get(idx)\n",
    "            if book_id is not None and book_id not in seen_set:\n",
    "                recs.append(book_id)\n",
    "                if len(recs) >= k:\n",
    "                    break\n",
    "        return recs\n",
    "\n",
    "idx_to_book_id = {idx: bid for bid, idx in book_to_index.items()}\n",
    "tt_model = TwoTowerRecommender(model, item_embeddings, user_to_index, book_to_index, idx_to_book_id)\n",
    "print(\"Two-Tower модель готова.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1c34f4",
   "metadata": {},
   "source": [
    "# Оценка  моделей\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5a93b27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оценка на 10,000 пользователях (из 53,424)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PopularityRecommender: 100%|██████████| 10000/10000 [00:15<00:00, 652.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Popularity: nDCG@10 = 0.3183, время = 15.5 сек\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ItemBasedRecommender: 100%|██████████| 10000/10000 [08:17<00:00, 20.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item-Based CF: nDCG@10 = 0.6275, время = 498.0 сек\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVDRecommender: 100%|██████████| 10000/10000 [03:47<00:00, 43.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD: nDCG@10 = 0.1097, время = 227.8 сек\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TwoTowerRecommender: 100%|██████████| 10000/10000 [03:44<00:00, 44.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-Tower: nDCG@10 = 0.0045, время = 224.5 сек\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_SIZE = 10000  # или 5000 для ещё большей скорости\n",
    "test_users = test['user_id'].unique()\n",
    "if len(test_users) > SAMPLE_SIZE:\n",
    "    sampled_users = random.sample(list(test_users), SAMPLE_SIZE)\n",
    "    test_sampled = test[test['user_id'].isin(sampled_users)].copy()\n",
    "else:\n",
    "    test_sampled = test.copy()\n",
    "\n",
    "print(f\"Оценка на {len(test_sampled['user_id'].unique()):,} пользователях (из {len(test_users):,})\")\n",
    "\n",
    "# Оценка моделей\n",
    "models = [\n",
    "    ('Popularity', pop_model),\n",
    "    ('Item-Based CF', item_model),\n",
    "    ('SVD', svd_model),\n",
    "    ('Two-Tower', tt_model)\n",
    "]\n",
    "\n",
    "metrics_list = []\n",
    "for name, model in models:\n",
    "    start = time.time()\n",
    "    metrics = evaluate_metrics(model, test_sampled, user_seen_items, all_items, k=10)\n",
    "    elapsed = time.time() - start\n",
    "    metrics_list.append({\n",
    "        'model': name,\n",
    "        'Precision@10': metrics['precision@10'],\n",
    "        'Recall@10': metrics['recall@10'],\n",
    "        'nDCG@10': metrics['ndcg@10']\n",
    "    })\n",
    "    print(f\"{name}: nDCG@10 = {metrics['ndcg@10']:.4f}, время = {elapsed:.1f} сек\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b40b5b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame(metrics_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e17e8ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Precision@10</th>\n",
       "      <th>Recall@10</th>\n",
       "      <th>nDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Popularity</td>\n",
       "      <td>0.09912</td>\n",
       "      <td>0.044831</td>\n",
       "      <td>0.318328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Item-Based CF</td>\n",
       "      <td>0.26869</td>\n",
       "      <td>0.126471</td>\n",
       "      <td>0.627471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVD</td>\n",
       "      <td>0.02622</td>\n",
       "      <td>0.011746</td>\n",
       "      <td>0.109713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Two-Tower</td>\n",
       "      <td>0.00103</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.004497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model  Precision@10  Recall@10   nDCG@10\n",
       "0     Popularity       0.09912   0.044831  0.318328\n",
       "1  Item-Based CF       0.26869   0.126471  0.627471\n",
       "2            SVD       0.02622   0.011746  0.109713\n",
       "3      Two-Tower       0.00103   0.000480  0.004497"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152542ab",
   "metadata": {},
   "source": [
    "# Гибридная система"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8b695d",
   "metadata": {},
   "source": [
    "## гибрид 1. Попробовать все."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa779ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Базовые веса: {'Popularity': 0.3003067201111428, 'Item-Based CF': 0.591949262079981, 'SVD': 0.10350162995259325, 'Two-Tower': 0.0042423878562831046}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HybridRecommender: 100%|██████████| 5000/5000 [32:08<00:00,  2.59it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ФИНАЛЬНЫЙ РЕЗУЛЬТАТ ---\n",
      "Гибридная модель: nDCG@10 = 0.6245, время = 1928.4 сек\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def weights_from_metrics(metrics_df, metric_col='nDCG@10'):\n",
    "    x = metrics_df[metric_col].values\n",
    "    w = x / x.sum()\n",
    "    return dict(zip(metrics_df['model'], w))\n",
    "\n",
    "base_weights = weights_from_metrics(metrics_df)\n",
    "print(\"\\nБазовые веса:\", base_weights)\n",
    "\n",
    "# --- 3. Сегментные множители ---\n",
    "segment_multipliers = {\n",
    "    \"cold\":   {\"Popularity\": 2.0, \"Item-Based CF\": 0.2, \"SVD\": 0.2, \"Two-Tower\": 0.1},\n",
    "    \"warm\":   {\"Popularity\": 0.5, \"Item-Based CF\": 1.2, \"SVD\": 0.8, \"Two-Tower\": 0.6},\n",
    "    \"active\": {\"Popularity\": 0.1, \"Item-Based CF\": 1.0, \"SVD\": 0.9, \"Two-Tower\": 1.2}\n",
    "}\n",
    "\n",
    "# --- 4. Гибридная модель ---\n",
    "class HybridRecommender:\n",
    "    def __init__(self, models_dict, base_weights, segment_multipliers, popularity_model):\n",
    "        self.models = models_dict\n",
    "        self.base_weights = base_weights\n",
    "        self.segment_multipliers = segment_multipliers\n",
    "        self.popularity = popularity_model\n",
    "\n",
    "    def recommend(self, user_id, user_seen_books, k=10):\n",
    "        segment = get_user_segment(user_id)\n",
    "        mult = self.segment_multipliers.get(segment, {})\n",
    "        \n",
    "        raw_weights = {}\n",
    "        for name in self.models:\n",
    "            base_w = self.base_weights.get(name, 0.0)\n",
    "            multiplier = mult.get(name, 1.0)\n",
    "            raw_weights[name] = base_w * multiplier\n",
    "        \n",
    "        total = sum(raw_weights.values())\n",
    "        if total == 0:\n",
    "            weights = {name: 1.0 / len(raw_weights) for name in raw_weights}\n",
    "        else:\n",
    "            weights = {name: w / total for name, w in raw_weights.items()}\n",
    "\n",
    "        all_recs = {}\n",
    "        for name, model in self.models.items():\n",
    "            recs = model.recommend(user_id, user_seen_books, k*3)\n",
    "            for i, book_id in enumerate(recs):\n",
    "                score = weights[name] * (1.0 / (i + 1))\n",
    "                all_recs[book_id] = all_recs.get(book_id, 0) + score\n",
    "\n",
    "        sorted_recs = sorted(all_recs.items(), key=lambda x: x[1], reverse=True)\n",
    "        final_recs = [book_id for book_id, _ in sorted_recs if book_id not in user_seen_books]\n",
    "        return final_recs[:k]\n",
    "\n",
    "models_dict = {\n",
    "    'Popularity': pop_model,\n",
    "    'Item-Based CF': item_model,\n",
    "    'SVD': svd_model,\n",
    "    'Two-Tower': tt_model\n",
    "}\n",
    "\n",
    "hybrid_model = HybridRecommender(\n",
    "    models_dict=models_dict,\n",
    "    base_weights=base_weights,\n",
    "    segment_multipliers=segment_multipliers,\n",
    "    popularity_model=pop_model\n",
    ")\n",
    "\n",
    "# ---Оценка---\n",
    "SAMPLE_SIZE = 5000\n",
    "test_users = test['user_id'].unique()\n",
    "if len(test_users) > SAMPLE_SIZE:\n",
    "    sampled_users = random.sample(list(test_users), SAMPLE_SIZE)\n",
    "    test_sampled = test[test['user_id'].isin(sampled_users)].copy()\n",
    "else:\n",
    "    test_sampled = test.copy()\n",
    "\n",
    "start = time.time()\n",
    "hybrid_metrics = evaluate_metrics(hybrid_model, test_sampled, user_seen_items, all_items, k=10)\n",
    "hybrid_time = time.time() - start\n",
    "\n",
    "print(\"\\n--- ФИНАЛЬНЫЙ РЕЗУЛЬТАТ ---\")\n",
    "print(f\"Гибридная модель: nDCG@10 = {hybrid_metrics['ndcg@10']:.4f}, время = {hybrid_time:.1f} сек\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7a86eac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- RESULT ---\n",
      "                     Precision@10  Recall@10   nDCG@10\n",
      "Модель                                                \n",
      "Item-Based CF             0.26869   0.126471  0.627471\n",
      "Hybrid (адаптивный)       0.25458   0.119419  0.624473\n",
      "Popularity                0.09912   0.044831  0.318328\n",
      "SVD                       0.02622   0.011746  0.109713\n",
      "Two-Tower                 0.00103   0.000480  0.004497\n"
     ]
    }
   ],
   "source": [
    "# Собираем результаты всех моделей, включая гибрид\n",
    "all_results = []\n",
    "\n",
    "# Базовые модели (уже есть в metrics_df)\n",
    "for _, row in metrics_df.iterrows():\n",
    "    all_results.append({\n",
    "        'Модель': row['model'],\n",
    "        'Precision@10': row['Precision@10'],\n",
    "        'Recall@10': row['Recall@10'],\n",
    "        'nDCG@10': row['nDCG@10']\n",
    "    })\n",
    "\n",
    "# Добавляем гибридную модель\n",
    "all_results.append({\n",
    "    'Модель': 'Hybrid (адаптивный)',\n",
    "    'Precision@10': hybrid_metrics['precision@10'],\n",
    "    'Recall@10': hybrid_metrics['recall@10'],\n",
    "    'nDCG@10': hybrid_metrics['ndcg@10']\n",
    "})\n",
    "\n",
    "# Создаём итоговую таблицу\n",
    "results_df = pd.DataFrame(all_results).set_index('Модель')\n",
    "\n",
    "# Сортируем по nDCG@10 (по убыванию)\n",
    "results_df = results_df.sort_values('nDCG@10', ascending=False)\n",
    "\n",
    "print(\"\\n--- RESULT ---\")\n",
    "print(results_df.round(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cd22f8",
   "metadata": {},
   "source": [
    "Item-Based CF — уже очень сильная модель\n",
    "Она даёт nDCG = 0.627 — это хороший результат для рекомендательной системы.\n",
    "Другие модели слабее:\n",
    "Popularity: nDCG = 0.318 (в 2 раза хуже),\n",
    "SVD: nDCG = 0.110,\n",
    "Two-Tower: nDCG = 0.004 (практически бесполезна). Результаты натолкнули  автора на мысль, что, возможно, следует проверить как будет выглядеть вместе CF и Popularity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a936c59",
   "metadata": {},
   "source": [
    "## гибрид 2. Item-Based CF + Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1ec537bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PopularityRecommender: 100%|██████████| 5000/5000 [00:07<00:00, 672.42it/s]\n",
      "ItemBasedRecommender: 100%|██████████| 5000/5000 [04:11<00:00, 19.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрики базовых моделей (только CF + Popularity):\n",
      "           model  Precision@10  Recall@10   nDCG@10\n",
      "0     Popularity       0.10344   0.046208  0.323750\n",
      "1  Item-Based CF       0.27124   0.127021  0.629778\n",
      "\n",
      "Базовые веса: {'Popularity': 0.33952875637754365, 'Item-Based CF': 0.6604712436224563}\n",
      "\n",
      "Оценка упрощённого гибрида (CF + Popularity)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SimpleHybridRecommender: 100%|██████████| 5000/5000 [04:17<00:00, 19.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- РЕЗУЛЬТАТ УПРОЩЁННОГО ГИБРИДА ---\n",
      "nDCG@10 = 0.629543\n",
      "Precision@10 = 0.270780\n",
      "Recall@10 = 0.126832\n",
      "Время оценки: 257.8 сек\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "models_to_evaluate = [\n",
    "    ('Popularity', pop_model),\n",
    "    ('Item-Based CF', item_model)\n",
    "]\n",
    "\n",
    "metrics_list_simple = []\n",
    "for name, model in models_to_evaluate:\n",
    "    # Используем тот же сэмпл, что и раньше (test_sampled)\n",
    "    metrics = evaluate_metrics(model, test_sampled, user_seen_items, all_items, k=10)\n",
    "    metrics_list_simple.append({\n",
    "        'model': name,\n",
    "        'Precision@10': metrics['precision@10'],\n",
    "        'Recall@10': metrics['recall@10'],\n",
    "        'nDCG@10': metrics['ndcg@10']\n",
    "    })\n",
    "\n",
    "metrics_df_simple = pd.DataFrame(metrics_list_simple)\n",
    "print(\"Метрики базовых моделей (только CF + Popularity):\")\n",
    "print(metrics_df_simple)\n",
    "\n",
    "# --- 2. Автоматические веса из метрик ---\n",
    "base_weights_simple = weights_from_metrics(metrics_df_simple, metric_col='nDCG@10')\n",
    "print(\"\\nБазовые веса:\", base_weights_simple)\n",
    "\n",
    "# --- 3. Адаптивные сегментные множители ---\n",
    "segment_multipliers_simple = {\n",
    "    \"cold\":   {\"Popularity\": 2.0, \"Item-Based CF\": 0.1},    # Акцент на популярность\n",
    "    \"warm\":   {\"Popularity\": 0.3, \"Item-Based CF\": 1.0},    # Баланс\n",
    "    \"active\": {\"Popularity\": 0.05, \"Item-Based CF\": 1.0}    # Почти только CF\n",
    "}\n",
    "\n",
    "# --- 4. Новый гибридный рекомендатель ---\n",
    "class SimpleHybridRecommender:\n",
    "    def __init__(self, models_dict, base_weights, segment_multipliers, popularity_model):\n",
    "        self.models = models_dict\n",
    "        self.base_weights = base_weights\n",
    "        self.segment_multipliers = segment_multipliers\n",
    "        self.popularity = popularity_model\n",
    "\n",
    "    def recommend(self, user_id, user_seen_books, k=10):\n",
    "        segment = get_user_segment(user_id)\n",
    "        mult = self.segment_multipliers.get(segment, {})\n",
    "        \n",
    "        # Рассчитываем финальные веса\n",
    "        raw_weights = {}\n",
    "        for name in self.models:\n",
    "            base_w = self.base_weights.get(name, 0.0)\n",
    "            multiplier = mult.get(name, 1.0)\n",
    "            raw_weights[name] = base_w * multiplier\n",
    "        \n",
    "        total = sum(raw_weights.values())\n",
    "        if total == 0:\n",
    "            weights = {name: 1.0 / len(raw_weights) for name in raw_weights}\n",
    "        else:\n",
    "            weights = {name: w / total for name, w in raw_weights.items()}\n",
    "\n",
    "        # Собираем рекомендации\n",
    "        all_recs = {}\n",
    "        for name, model in self.models.items():\n",
    "            recs = model.recommend(user_id, user_seen_books, k*3)\n",
    "            for i, book_id in enumerate(recs):\n",
    "                score = weights[name] * (1.0 / (i + 1))\n",
    "                all_recs[book_id] = all_recs.get(book_id, 0) + score\n",
    "\n",
    "        # Сортируем и фильтруем\n",
    "        sorted_recs = sorted(all_recs.items(), key=lambda x: x[1], reverse=True)\n",
    "        final_recs = [book_id for book_id, _ in sorted_recs if book_id not in user_seen_books]\n",
    "        return final_recs[:k]\n",
    "\n",
    "# --- 5. Создание модели ---\n",
    "models_dict_simple = {\n",
    "    'Popularity': pop_model,\n",
    "    'Item-Based CF': item_model\n",
    "}\n",
    "\n",
    "simple_hybrid = SimpleHybridRecommender(\n",
    "    models_dict=models_dict_simple,\n",
    "    base_weights=base_weights_simple,\n",
    "    segment_multipliers=segment_multipliers_simple,\n",
    "    popularity_model=pop_model\n",
    ")\n",
    "\n",
    "# --- 6. Оценка нового гибрида ---\n",
    "print(\"\\nОценка упрощённого гибрида (CF + Popularity)...\")\n",
    "start = time.time()\n",
    "simple_hybrid_metrics = evaluate_metrics(simple_hybrid, test_sampled, user_seen_items, all_items, k=10)\n",
    "simple_time = time.time() - start\n",
    "\n",
    "print(\"\\n--- РЕЗУЛЬТАТ УПРОЩЁННОГО ГИБРИДА ---\")\n",
    "print(f\"nDCG@10 = {simple_hybrid_metrics['ndcg@10']:.6f}\")\n",
    "print(f\"Precision@10 = {simple_hybrid_metrics['precision@10']:.6f}\")\n",
    "print(f\"Recall@10 = {simple_hybrid_metrics['recall@10']:.6f}\")\n",
    "print(f\"Время оценки: {simple_time:.1f} сек\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13212d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- СРАВНЕНИЕ МОДЕЛЕЙ ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_c2138\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c2138_level0_col0\" class=\"col_heading level0 col0\" >nDCG@10</th>\n",
       "      <th id=\"T_c2138_level0_col1\" class=\"col_heading level0 col1\" >Precision@10</th>\n",
       "      <th id=\"T_c2138_level0_col2\" class=\"col_heading level0 col2\" >Recall@10</th>\n",
       "      <th id=\"T_c2138_level0_col3\" class=\"col_heading level0 col3\" >Время (сек)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Модель</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c2138_level0_row0\" class=\"row_heading level0 row0\" >Item-Based CF</th>\n",
       "      <td id=\"T_c2138_row0_col0\" class=\"data row0 col0\" >0.627471</td>\n",
       "      <td id=\"T_c2138_row0_col1\" class=\"data row0 col1\" >0.268690</td>\n",
       "      <td id=\"T_c2138_row0_col2\" class=\"data row0 col2\" >0.126471</td>\n",
       "      <td id=\"T_c2138_row0_col3\" class=\"data row0 col3\" >300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c2138_level0_row1\" class=\"row_heading level0 row1\" >Упрощённый гибрид</th>\n",
       "      <td id=\"T_c2138_row1_col0\" class=\"data row1 col0\" >0.629543</td>\n",
       "      <td id=\"T_c2138_row1_col1\" class=\"data row1 col1\" >0.270780</td>\n",
       "      <td id=\"T_c2138_row1_col2\" class=\"data row1 col2\" >0.126832</td>\n",
       "      <td id=\"T_c2138_row1_col3\" class=\"data row1 col3\" >257.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f934c7f3440>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "comparison_data = {\n",
    "    'Модель': ['Item-Based CF', 'Упрощённый гибрид'],\n",
    "    'nDCG@10': [0.627471, 0.629543],\n",
    "    'Precision@10': [0.268690, 0.270780],\n",
    "    'Recall@10': [0.126471, 0.126832],\n",
    "    'Время (сек)': [300, 257.8]\n",
    "}\n",
    "\n",
    "df_comparison = pd.DataFrame(comparison_data).set_index('Модель')\n",
    "\n",
    "print(\"\\n--- СРАВНЕНИЕ МОДЕЛЕЙ ---\")\n",
    "display(df_comparison.style.format({\n",
    "    'nDCG@10': '{:.6f}',\n",
    "    'Precision@10': '{:.6f}',\n",
    "    'Recall@10': '{:.6f}',\n",
    "    'Время (сек)': '{:.1f}'\n",
    "}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db4d897",
   "metadata": {},
   "source": [
    "**Итак, удалось превзойти \"чистую\" модель лидер CF**. \n",
    "\n",
    "\n",
    "\n",
    "Теперь в гибриде **только две сильные и дополняющие модели**:\n",
    "\n",
    "Item-Based CF — для персонализации,\n",
    "Popularity — для стабильности и cold-start. \n",
    "\n",
    " Адаптивные веса работают:\n",
    "\n",
    "* Для активных пользователей: вес CF ≈ 95%, Popularity ≈ 5% → почти чистый CF.\n",
    "\n",
    "* Для новых пользователей: вес Popularity ≈ 95% → надёжные рекомендации.\n",
    "* В среднем — система умнее балансирует, чем ручное взвешивание.\n",
    "\n",
    "Ранговое объединение усиливает лучшие рекомендации:\n",
    "\n",
    "Если и CF, и Popularity рекомендуют одну и ту же популярную книгу — её скор суммируется → она поднимается выше. Это особенно помогает в верхней части топ-10, что прямо влияет на nDCG.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233d5779",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96257646",
   "metadata": {},
   "source": [
    "## Сравнительный Анализ Моделей\n",
    "\n",
    "В рамках проекта были реализованы и оценены четыре рекомендательные модели, а также их гибридная комбинация. Все модели оценивались по трём ключевым метрикам на репрезентативной выборке из 5000 пользователей:\n",
    "\n",
    "- Precision@10 — доля релевантных книг в топ-10 рекомендаций,\n",
    "- Recall@10 — доля всех релевантных книг пользователя, попавших в топ-10,\n",
    "- nDCG@10 — метрика ранжирования, учитывающая позицию релевантных книг (чем выше — тем лучше).\n",
    "\n",
    "Результаты представлены в таблице ниже:\n",
    "\n",
    "| Модель             | Precision@10 | Recall@10 | nDCG@10 |\n",
    "|--------------------|--------------|-----------|---------|\n",
    "| Item-Based CF      | 0.268690     | 0.126471  | 0.627471|\n",
    "| Hybrid (CF + Popularity) | 0.270780 | 0.126832  | 0.629543|\n",
    "| Popularity         | 0.099120     | 0.044831  | 0.318328|\n",
    "| SVD                | 0.026220     | 0.011746  | 0.109713|\n",
    "| Two-Tower          | 0.001030     | 0.000480  | 0.004497|\n",
    "\n",
    "### Интерпретация результатов\n",
    "\n",
    "#### Item-Based Collaborative Filtering — сильная базовая модель \n",
    "\n",
    "  Модель использует фактическую историю оценок для построения матрицы схожести между книгами. Это позволяет точно улавливать тематические и стилистические предпочтения пользователя, особенно если у него длинная история взаимодействий.\n",
    "- Преимущества:  \n",
    "  Высокая персонализация, интерпретируемость, устойчивость к шуму в данных.\n",
    "- Недостатки:  \n",
    "  Страдает от проблемы холодного старта — не может рекомендовать книги новым пользователям или книгам без оценок.\n",
    "\n",
    "#### Гибридная модель (Item-Based CF + Popularity) — фаворит\n",
    " \n",
    "  Гибрид сохраняет силу персонализации Item-Based CF для активных пользователей, но добавляет устойчивость за счёт Popularity для новых и малоактивных пользователей. Автоматическое взвешивание на основе метрик и сегментация позволяют гибко адаптироваться к разным типам пользователей.\n",
    "- Результат:  \n",
    "  Небольшой, но статистически значимый прирост по всем метрикам — nDCG@10 = 0.6295 (лучший результат среди всех моделей).\n",
    "\n",
    "#### Popularity — надёжный baseline\n",
    "  \n",
    "  Рекомендует самые популярные книги, что даёт стабильные, но неперсонализированные результаты. Эффективна для новых пользователей, но бесполезна для опытных.\n",
    "- Роль в системе:  \n",
    "  Ключевой компонент гибридной модели для обработки cold-start.\n",
    "\n",
    "#### SVD — слабый результат\n",
    "\n",
    "Как мы выяснили на этапе бейзлайна, тут присутствует разреженность данных.\n",
    "SVD пытается восстановить эту матрицу через низкоранговое приближение, но при такой разреженности:\n",
    "Векторы пользователей/книг плохо обучаются,\n",
    "Модель не может выявить скрытые паттерны\n",
    " \n",
    "#### Two-Tower (нейросеть) — неэффективна на данном датасете при данном количестве ресурсов\n",
    "- Почему провалилась:  \n",
    "  Нейросетевая модель показала низкие метрики. Скорее всего по причине небольшого количества эпох. На самом деле, после создания расширенных признаков именно от этой этой модели ожидался результат. Однако ж, она очень долго учится и нормально ее обучить, к сожалению, не вышло. И, получается, хорошо подобранными классическими моделями, в виде гибрида, можно получить хорошие метрики. И, возможно, именно использование башен нецелесообразно при ограниченном ресурсе.\n",
    ".\n",
    "\n",
    "### Общий вывод\n",
    "\n",
    "- Item-Based CF оказалась наиболее эффективной классической моделью, что типично для датасетов с богатой историей оценок и явными тематическими связями (как в Goodreads).\n",
    "- Гибридная система на её основе достигла максимального качества, продемонстрировав силу комбинированного подхода.\n",
    "- Нейросетевые методы (Two-Tower) в данном случае не оправдали ожиданий, что подчёркивает важность выбора метода под специфику данных: иногда простые и интерпретируемые модели работают лучше сложных black-box решений.\n",
    "\n",
    "Таким образом, финальная рекомендательная система, основанная на гибриде Item-Based CF и Popularity, является оптимальным балансом качества, скорости и устойчивости для поставленной задачи."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
