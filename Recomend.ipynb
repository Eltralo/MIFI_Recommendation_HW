{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d39823fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split as sklearn_train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from surprise import Reader, Dataset, SVD\n",
    "from surprise import accuracy\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2b55c48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "books = pd.read_csv('/home/administrator/Desktop/IDE/Recomendation/books_new.csv')\n",
    "ratings = pd.read_csv('/home/administrator/Desktop/IDE/Recomendation/ratings.csv')\n",
    "tags =  pd.read_csv('/home/administrator/Desktop/IDE/Recomendation/tags.csv')\n",
    "book_tags = pd.read_csv('/home/administrator/Desktop/IDE/Recomendation/book_tags.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05174da7",
   "metadata": {},
   "source": [
    "## ФУНКЦИЯ РАЗДЕЛЕНИЯ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ac9c0c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_random_ratings(ratings, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Случайное разделение датасета рейтингов\n",
    "    \"\"\"\n",
    "    print(\"Выполняется случайное разделение данных...\")\n",
    "    start_time = time.time()\n",
    "    train, test = sklearn_train_test_split(ratings, test_size=test_size, random_state=42)\n",
    "    elapsed = time.time() - start_time\n",
    "    return train, test, elapsed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d02b64b",
   "metadata": {},
   "source": [
    "## ФУНКЦИЯ ОЦЕНКИ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "20c79206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Оптимизированная функция оценки настроена (с поддержкой ID-моделей).\n"
     ]
    }
   ],
   "source": [
    "def optimized_evaluate_metrics(recommender, test_data, user_seen_items_dict, all_items, k=10):\n",
    "    \"\"\"Оценка Top-K рекомендаций по метрикам.\"\"\"\n",
    "    test_user_items = test_data.groupby('user_id')['book_id'].agg(list).to_dict()\n",
    "    catalog_size = len(all_items)\n",
    "\n",
    "    precision_sum = 0\n",
    "    recall_sum = 0\n",
    "    ndcg_sum = 0\n",
    "    arp_sum = 0\n",
    "    hit_rate_sum = 0\n",
    "    catalog_coverage = set()\n",
    "    users_evaluated = 0\n",
    "\n",
    "    for user_id, true_items in test_user_items.items():\n",
    "        if not true_items:\n",
    "            continue\n",
    "\n",
    "        user_history = user_seen_items_dict.get(user_id, set())\n",
    "        \n",
    "        # для SVD\n",
    "        if hasattr(recommender, 'requires_user_id') and recommender.requires_user_id:\n",
    "            # Для SVD\n",
    "            recs = recommender.recommend(user_id, user_history, k=k)\n",
    "        else:\n",
    "            # Для Popularity, Content-Based: Передаем только user_history и k\n",
    "            recs = recommender.recommend(user_history, k=k)\n",
    "        # ------------------------------------------------------------------------\n",
    "\n",
    "        if not recs:\n",
    "            continue\n",
    "\n",
    "        users_evaluated += 1\n",
    "        catalog_coverage.update(recs)\n",
    "\n",
    "        rec_set = set(recs)\n",
    "        true_set = set(true_items)\n",
    "        hits = rec_set & true_set\n",
    "        num_hits = len(hits)\n",
    "\n",
    "        # Precision и Recall\n",
    "        precision = num_hits / len(recs)\n",
    "        recall = num_hits / len(true_set)\n",
    "\n",
    "        precision_sum += precision\n",
    "        recall_sum += recall\n",
    "        hit_rate_sum += 1 if num_hits > 0 else 0\n",
    "\n",
    "        # nDCG\n",
    "        relevance = [1 if item in true_set else 0 for item in recs]\n",
    "        if num_hits > 0:\n",
    "            ideal = sorted(relevance, reverse=True)\n",
    "            dcg = sum(r / np.log2(i + 2) for i, r in enumerate(relevance))\n",
    "            idcg = sum(r / np.log2(i + 2) for i, r in enumerate(ideal))\n",
    "            ndcg = dcg / idcg\n",
    "        else:\n",
    "            ndcg = 0\n",
    "        ndcg_sum += ndcg\n",
    "\n",
    "        # ARP\n",
    "        arp_score = sum(1 / (i + 1) for i, item in enumerate(recs) if item in true_set)\n",
    "        arp_sum += arp_score / len(recs)\n",
    "\n",
    "    coverage = len(catalog_coverage) / catalog_size if catalog_size > 0 else 0\n",
    "\n",
    "    return {\n",
    "        'precision@10': precision_sum / users_evaluated if users_evaluated > 0 else 0,\n",
    "        'recall@10': recall_sum / users_evaluated if users_evaluated > 0 else 0,\n",
    "        'ndcg@10': ndcg_sum / users_evaluated if users_evaluated > 0 else 0,\n",
    "        'arp@10': arp_sum / users_evaluated if users_evaluated > 0 else 0,\n",
    "        'hit_rate@10': hit_rate_sum / users_evaluated if users_evaluated > 0 else 0,\n",
    "        'coverage': coverage,\n",
    "        'users_evaluated': users_evaluated\n",
    "    }\n",
    "\n",
    "print(\"\\n Оптимизированная функция оценки настроена (с поддержкой ID-моделей).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406f68fb",
   "metadata": {},
   "source": [
    "##  МОДЕЛЬ 1: МОДЕЛЬ ОСНОВАННАЯ НА ПОПУЛЯРНОСТИ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbc0ee1",
   "metadata": {},
   "source": [
    "**Эта модель рекомендует всем пользователям одни и те же популярные книги. Под \"популярными\" мы будем понимать книги с высоким средним рейтингом и значительным количеством оценок для обеспечения надежности.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a3a00aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Выполняется случайное разделение данных...\n",
      "\n",
      "ФИНАЛЬНОЕ РАЗДЕЛЕНИЕ (Случайное):\n",
      "  train: 4,781,183 записей\n",
      "  test:  1,195,296 записей\n"
     ]
    }
   ],
   "source": [
    "train, test, split_time = split_random_ratings(ratings, test_size=0.2)\n",
    "\n",
    "print(f\"\\nФИНАЛЬНОЕ РАЗДЕЛЕНИЕ (Случайное):\")\n",
    "print(f\"  train: {len(train):,} записей\")\n",
    "print(f\"  test:  {len(test):,} записей\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d66ced1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Пользователей для оценки: 53,423\n"
     ]
    }
   ],
   "source": [
    "all_items = ratings['book_id'].unique()\n",
    "\n",
    "# История просмотров/оценок по пользователям (из train)\n",
    "user_seen_items = train.groupby('user_id')['book_id'].agg(set).to_dict()\n",
    "\n",
    "# Оставляем только пользователей, которые есть и в train, и в test (для корректной оценки)\n",
    "common_users = set(train['user_id']) & set(test['user_id'])\n",
    "test_filtered = test[test['user_id'].isin(common_users)].copy()\n",
    "\n",
    "print(f\"  Пользователей для оценки: {len(common_users):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e41f0b2",
   "metadata": {},
   "source": [
    "**Мы оцениваем только на 53,423 пользователях потому что:**\n",
    "\n",
    "* У них есть история в train (можно строить рекомендации)\n",
    "\n",
    "* У них есть реальные взаимодействия в test (можно измерить качество)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5dad7443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Обучение модели...\n",
      "Обучение Popularity-модели...\n",
      "Оценка модели...\n",
      "\n",
      "РЕЗУЛЬТАТЫ POPULARITY МОДЕЛИ:\n",
      "  NDCG@10:    0.3181\n",
      "  Precision@10: 0.1019\n",
      "  Recall@10:    0.0456\n",
      "  ARP@10:       0.0363\n",
      "  HitRate@10:   51.47%\n",
      "  Coverage:     0.44%\n",
      "  Время обучения: 0.3 сек\n",
      "  Время оценки:   3.2 сек\n"
     ]
    }
   ],
   "source": [
    "class PopularityRecommender:\n",
    "    def __init__(self):\n",
    "        self.popular_books = None\n",
    "\n",
    "    def fit(self, train_data):\n",
    "        print(\"Обучение Popularity-модели...\")\n",
    "        # Сортируем по популярности (количеству оценок)\n",
    "        self.popular_books = train_data['book_id'].value_counts().index.tolist()\n",
    "\n",
    "    def recommend(self, user_seen_books, k=10):\n",
    "        if not self.popular_books:\n",
    "            return []\n",
    "        seen_set = set(user_seen_books)\n",
    "        recs = []\n",
    "        for book in self.popular_books:\n",
    "            if book not in seen_set:\n",
    "                recs.append(book)\n",
    "                if len(recs) >= k:\n",
    "                    break\n",
    "        return recs\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6. Обучение и оценка\n",
    "# ------------------------------------------------------------\n",
    "print(\"\\nОбучение модели...\")\n",
    "start_time = time.time()\n",
    "pop_model = PopularityRecommender()\n",
    "pop_model.fit(train)\n",
    "train_time = time.time() - start_time\n",
    "\n",
    "print(\"Оценка модели...\")\n",
    "start_time = time.time()\n",
    "metrics = optimized_evaluate_metrics(pop_model, test_filtered, user_seen_items, all_items, k=10)\n",
    "eval_time = time.time() - start_time\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 7. Вывод результатов\n",
    "# ------------------------------------------------------------\n",
    "print(\"\\nРЕЗУЛЬТАТЫ POPULARITY МОДЕЛИ:\")\n",
    "print(f\"  NDCG@10:    {metrics['ndcg@10']:.4f}\")\n",
    "print(f\"  Precision@10: {metrics['precision@10']:.4f}\")\n",
    "print(f\"  Recall@10:    {metrics['recall@10']:.4f}\")\n",
    "print(f\"  ARP@10:       {metrics['arp@10']:.4f}\")\n",
    "print(f\"  HitRate@10:   {metrics['hit_rate@10']:.2%}\")\n",
    "print(f\"  Coverage:     {metrics['coverage']:.2%}\")\n",
    "print(f\"  Время обучения: {train_time:.1f} сек\")\n",
    "print(f\"  Время оценки:   {eval_time:.1f} сек\")\n",
    "\n",
    "# Сохраняем результаты\n",
    "results = [{\n",
    "    'Алгоритм': 'Popularity',\n",
    "    'NDCG@10': metrics['ndcg@10'],\n",
    "    'Precision@10': metrics['precision@10'],\n",
    "    'Recall@10': metrics['recall@10'],\n",
    "    'ARP@10': metrics['arp@10'],\n",
    "    'HitRate@10': metrics['hit_rate@10'],\n",
    "    'Coverage': metrics['coverage'],\n",
    "    'Время_обучения': train_time,\n",
    "    'Время_оценки': eval_time\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561ac83c",
   "metadata": {},
   "source": [
    "* Hit Rate@10 = 51.47%\n",
    "Popularity-модель ничего не знает о пользователе — она просто выдаёт общие хиты. То, что она \"попадает\" в интересы половины пользователей — уже неплохо.\n",
    "\n",
    "* Precision@10 = 10.19%\n",
    "Из 10 рекомендованных книг в среднем 1 книга окажется релевантной.\n",
    "\n",
    "* . Recall@10 = 4.56%\n",
    "Recall низкий — потому что большинство релевантных книг пользователя находятся в \"длинном хвосте\", а Popularity их не видит. \n",
    "\n",
    "* NDCG@10 = 0.3181\n",
    "одель умеет ранжировать (популярные книги действительно чаще релевантны), но не идеально.\n",
    "\n",
    "* Coverage = 0.44%\n",
    "Пользователи видят одни и те же книги.Нет разнообразия, нет открытий.\n",
    "Популярное становится ещё популярнее, и это так называемый эффект Мэтью.\n",
    "\n",
    "*   ARP@10 = 0.0363\n",
    "Если релевантная книга на 1-м месте → вклад = 1/1 = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd675ec",
   "metadata": {},
   "source": [
    "**Эта модель проста и эффективна для новых пользователей (холодный старт), но ей не хватает персонализации. Popularity-модель является самой быстрой и масштабируемой в обучении и генерации рекомендаций. Эта модель очень хороша как бейзлайн. Все последующие персонализированные модели (CF, SVD, Content-Based) должны показывать значимо лучшие результаты по метрикам Precision/Recall/NDCG, чтобы считаться успешными.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac824716",
   "metadata": {},
   "source": [
    "## Модель 2: Content-Based Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bd16b4",
   "metadata": {},
   "source": [
    "Эта модель рекомендует книги, похожие на данную книгу, на основе ее содержания (названия и тегов)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f349911",
   "metadata": {},
   "source": [
    "Подготовка данных\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4e346714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Подготовлено 10000 книг с контентными профилями.\n",
      "2. TF-IDF векторизация и расчёт схожести...\n",
      "  → Матрица схожести готова.\n"
     ]
    }
   ],
   "source": [
    "book_tags_with_names = pd.merge(book_tags, tags, on='tag_id')\n",
    "\n",
    "book_tags_agg = book_tags_with_names.groupby('goodreads_book_id')['tag_name'].apply(lambda x: ' '.join(x)).reset_index() # Агрегируем все теги по книге в одну строку\n",
    "\n",
    "books_with_tags = pd.merge(books, book_tags_agg, on='goodreads_book_id', how='left') # Присоединяем к книгам\n",
    "books_with_tags['tag_name'] = books_with_tags['tag_name'].fillna('')\n",
    "\n",
    "books_with_tags['content'] = books_with_tags['original_title'].fillna('') + ' ' + books_with_tags['tag_name'] # Создаём контентный профиль\n",
    "\n",
    "books_with_tags = books_with_tags.set_index('book_id') # Устанавливаем book_id как индекс для удобства\n",
    "\n",
    "print(f\"  → Подготовлено {len(books_with_tags)} книг с контентными профилями.\")\n",
    "\n",
    "#  Векторизация и матрица схожести\n",
    "\n",
    "print(\"2. TF-IDF векторизация и расчёт схожести...\")\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "tfidf_matrix = tfidf.fit_transform(books_with_tags['content'])\n",
    "\n",
    "cosine_sim = cosine_similarity(tfidf_matrix)\n",
    "\n",
    "# Создаём маппинги между book_id и индексом в матрице\n",
    "book_id_to_idx = {book_id: idx for idx, book_id in enumerate(books_with_tags.index)}\n",
    "idx_to_book_id = {idx: book_id for book_id, idx in book_id_to_idx.items()}\n",
    "\n",
    "print(\"  → Матрица схожести готова.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "862a52e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Подготовлено 10000 книг с контентными профилями.\n",
      "2. TF-IDF векторизация и расчёт схожести...\n",
      "  → Матрица схожести готова.\n",
      "\n",
      "3. Создание и оценка модели...\n",
      "\n",
      "РЕЗУЛЬТАТЫ CONTENT-BASED МОДЕЛИ:\n",
      "  NDCG@10:    0.2579\n",
      "  Precision@10: 0.0685\n",
      "  Recall@10:    0.0324\n",
      "  ARP@10:       0.0307\n",
      "  HitRate@10:   37.89%\n",
      "  Coverage:     75.74%\n",
      "  Время оценки: 408.3 сек\n",
      "\n",
      " Результаты добавлены в общий список.\n"
     ]
    }
   ],
   "source": [
    "class ContentBasedRecommender:\n",
    "    def __init__(self, books_with_tags, cosine_sim, book_id_to_idx, idx_to_book_id):\n",
    "        self.books_with_tags = books_with_tags\n",
    "        self.cosine_sim = cosine_sim\n",
    "        self.book_id_to_idx = book_id_to_idx\n",
    "        self.idx_to_book_id = idx_to_book_id\n",
    "\n",
    "    def recommend(self, user_seen_books, k=10):\n",
    "        \"\"\"\n",
    "        Генерирует рекомендации на основе истории пользователя.\n",
    "        Берёт последнюю книгу из истории как основу и находит похожие.\n",
    "        \"\"\"\n",
    "        # Фильтруем только те книги, которые есть в нашем контентном датасете\n",
    "        seen_in_catalog = [bid for bid in user_seen_books if bid in self.book_id_to_idx]\n",
    "        if not seen_in_catalog:\n",
    "            return []\n",
    "\n",
    "        # Берём последнюю книгу как основу\n",
    "        seed_book_id = seen_in_catalog[-1]\n",
    "\n",
    "        idx = self.book_id_to_idx[seed_book_id]\n",
    "        sim_scores = list(enumerate(self.cosine_sim[idx]))\n",
    "        # Сортируем по убыванию, пропускаем первую (саму себя)\n",
    "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:]\n",
    "\n",
    "        recs = []\n",
    "        seen_set = set(user_seen_books)\n",
    "        for i, score in sim_scores:\n",
    "            book_id = self.idx_to_book_id[i]\n",
    "            if book_id not in seen_set:\n",
    "                recs.append(book_id)\n",
    "                if len(recs) >= k:\n",
    "                    break\n",
    "        return recs\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. Создание и оценка модели\n",
    "# ------------------------------------------------------------\n",
    "print(\"\\n3. Создание и оценка модели...\")\n",
    "\n",
    "content_model = ContentBasedRecommender(\n",
    "    books_with_tags, cosine_sim, book_id_to_idx, idx_to_book_id\n",
    ")\n",
    "\n",
    "# Оценка\n",
    "start_time = time.time()\n",
    "metrics_content = optimized_evaluate_metrics(\n",
    "    content_model, test_filtered, user_seen_items, all_items, k=10\n",
    ")\n",
    "eval_time = time.time() - start_time\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5. Вывод результатов\n",
    "# ------------------------------------------------------------\n",
    "print(\"\\nРЕЗУЛЬТАТЫ CONTENT-BASED МОДЕЛИ:\")\n",
    "print(f\"  NDCG@10:    {metrics_content['ndcg@10']:.4f}\")\n",
    "print(f\"  Precision@10: {metrics_content['precision@10']:.4f}\")\n",
    "print(f\"  Recall@10:    {metrics_content['recall@10']:.4f}\")\n",
    "print(f\"  ARP@10:       {metrics_content['arp@10']:.4f}\")\n",
    "print(f\"  HitRate@10:   {metrics_content['hit_rate@10']:.2%}\")\n",
    "print(f\"  Coverage:     {metrics_content['coverage']:.2%}\")\n",
    "print(f\"  Время оценки: {eval_time:.1f} сек\")\n",
    "\n",
    "# Добавляем в общий список результатов (если есть)\n",
    "try:\n",
    "    results.append({\n",
    "        'Алгоритм': 'Content-Based',\n",
    "        'NDCG@10': metrics_content['ndcg@10'],\n",
    "        'Precision@10': metrics_content['precision@10'],\n",
    "        'Recall@10': metrics_content['recall@10'],\n",
    "        'ARP@10': metrics_content['arp@10'],\n",
    "        'HitRate@10': metrics_content['hit_rate@10'],\n",
    "        'Coverage': metrics_content['coverage'],\n",
    "        'Время_обучения': 0,  # обучение = подготовка матрицы (уже сделано)\n",
    "        'Время_оценки': eval_time\n",
    "    })\n",
    "    print(\"\\n Результаты добавлены в общий список.\")\n",
    "except NameError:\n",
    "    print(\"\\n Переменная 'results' не определена. Создаём новую.\")\n",
    "    results = [{\n",
    "        'Алгоритм': 'Content-Based',\n",
    "        'NDCG@10': metrics_content['ndcg@10'],\n",
    "        'Precision@10': metrics_content['precision@10'],\n",
    "        'Recall@10': metrics_content['recall@10'],\n",
    "        'ARP@10': metrics_content['arp@10'],\n",
    "        'HitRate@10': metrics_content['hit_rate@10'],\n",
    "        'Coverage': metrics_content['coverage'],\n",
    "        'Время_обучения': 0,\n",
    "        'Время_оценки': eval_time\n",
    "    }]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02efeac6",
   "metadata": {},
   "source": [
    "**Сильные стороны**\n",
    "\n",
    "Огромный Coverage (75.7%)\n",
    "→ Модель работает с \"длинным хвостом\", рекомендует нишевые книги, а не только бестселлеры.\n",
    "→ Это главное преимущество перед Popularity!\n",
    "Персонализация по содержанию\n",
    "→ Если пользователь читает \"японскую литературу\", модель предложит похожие книги, даже если они не популярны. \n",
    "\n",
    "Слабые стороны\n",
    "Низкие Precision, Recall, Hit Rate\n",
    "→ Контентные профили недостаточно точны. Причины:\n",
    "Шумные теги: много \"to-read\", \"favorites\" вместо жанров.\n",
    "Короткие профили: у многих книг мало тегов или только общие (\"fiction\").\n",
    "Нет учёта пользовательских предпочтений: модель не знает, нравится ли пользователю жанр — она просто ищет похожие книги.\n",
    "Хуже ранжирование (NDCG)\n",
    "→ Даже когда релевантные книги есть в рекомендациях, они не в топе списка.\n",
    "\n",
    "Контентная модель имеет высокую предварительную сложность O(N**2) и требует значительных ресурсов памяти, но после подготовки генерация рекомендаций для одного пользователя работает эффективно."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2328bf",
   "metadata": {},
   "source": [
    "В данном коде взята за основу  Content-Based на основе последней активности (Last-Item Recommendation). Почему выбран именно этот подход?\n",
    "\n",
    "* 1. Быстродействие. Модель крайне быстра в режиме рекомендаций. Поскольку матрица схожести N×N рассчитана заранее, генерация рекомендаций сводится к одной операции поиска по индексу (вместо сложной агрегации профиля)\n",
    "* 2. Актуальность. Пользовательские предпочтения постоянно меняются. Использование самого последнего прочитанного элемента (книги-основы) фокусирует рекомендательную систему на текущем, сиюминутном интересе пользователя, игнорируя его давнюю историю.\n",
    "* 3. Вычислительная эффективность. Подход позволяет избежать построения сложного профиля пользователя (агрегации TF-IDF векторов всех прочитанных книг), что существенно экономит вычислительные ресурсы и время, особенно если у пользователя очень длинная история (тысячи прочитанных книг).\n",
    "\n",
    "Слабая сторона: Главный недостаток — низкое качество (NDCG) и низкая точность. Модель игнорирует всю остальную историю и все оценки пользователя. Мы отказались от создания взвешенного профиля пользователя , который бы учитывал все прочитанные книги и их оценки, чтобы повысить NDCG и Precision из-за вычислительного огранияения. Взвешенный профиль требует агрегации (суммирования) TF-IDF векторов для всех прочитанных книг каждого пользователя.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0536b3b",
   "metadata": {},
   "source": [
    "## Модель 3. Collaborative Filtering (CF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9f6be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаём user-item матрицу\n",
    "print(\"1. Создание user-item матрицы...\")\n",
    "user_item_matrix = ratings.pivot_table(index='user_id', columns='book_id', values='rating')\n",
    "user_item_matrix.fillna(0, inplace=True)  # 0 = отсутствие оценки\n",
    "print(\"2. Расчёт схожести между книгами...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b1719c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Транспонируем: книги → строки\n",
    "item_similarity = cosine_similarity(user_item_matrix.T)\n",
    "item_sim_df = pd.DataFrame(\n",
    "    item_similarity,\n",
    "    index=user_item_matrix.columns,   # book_id\n",
    "    columns=user_item_matrix.columns  # book_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8df166e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ITEM-BASED COLLABORATIVE FILTERING ===\n",
      "1. Создание user-item матрицы...\n",
      "2. Расчёт схожести между книгами...\n",
      "  → Матрица схожести книг готова.\n",
      "\n",
      "3. Создание и оценка модели...\n",
      "\n",
      "РЕЗУЛЬТАТЫ ITEM-BASED CF МОДЕЛИ:\n",
      "  NDCG@10:    0.6305\n",
      "  Precision@10: 0.2738\n",
      "  Recall@10:    0.1281\n",
      "  ARP@10:       0.1025\n",
      "  HitRate@10:   85.89%\n",
      "  Coverage:     29.10%\n",
      "  Время оценки: 1553.8 сек\n",
      "\n",
      "✅ Item-Based CF успешно оценена!\n"
     ]
    }
   ],
   "source": [
    "class ItemBasedRecommender:\n",
    "    def __init__(self, item_sim_df):\n",
    "        self.item_sim_df = item_sim_df\n",
    "\n",
    "    def recommend(self, user_seen_books, k=10):\n",
    "        \"\"\"\n",
    "        Генерирует рекомендации на основе истории пользователя.\n",
    "        Для каждой книги пользователя находит похожие и агрегирует схожесть.\n",
    "        \"\"\"\n",
    "        if not user_seen_books:\n",
    "            return []\n",
    "\n",
    "        # Оставляем только книги, которые есть в матрице схожести\n",
    "        seen_in_catalog = [bid for bid in user_seen_books if bid in self.item_sim_df.index]\n",
    "        if not seen_in_catalog:\n",
    "            return []\n",
    "\n",
    "        # Агрегируем схожесть: суммируем scores по всем просмотренным книгам\n",
    "        similarity_scores = pd.Series(dtype='float64')\n",
    "        for book_id in seen_in_catalog:\n",
    "            sim_scores = self.item_sim_df[book_id]\n",
    "            similarity_scores = similarity_scores.add(sim_scores, fill_value=0)\n",
    "\n",
    "        # Исключаем уже просмотренные книги\n",
    "        similarity_scores = similarity_scores.drop(seen_in_catalog, errors='ignore')\n",
    "\n",
    "        # Берём топ-k\n",
    "        top_books = similarity_scores.nlargest(k)\n",
    "        return top_books.index.tolist()\n",
    "\n",
    "# 4. Оценка модели\n",
    "print(\"\\n3. Создание и оценка модели...\")\n",
    "\n",
    "item_model = ItemBasedRecommender(item_sim_df)\n",
    "\n",
    "start_time = time.time()\n",
    "metrics_item = optimized_evaluate_metrics(\n",
    "    item_model, test_filtered, user_seen_items, all_items, k=10\n",
    ")\n",
    "eval_time = time.time() - start_time\n",
    "\n",
    "# 5. Вывод результатов\n",
    "print(\"\\nРЕЗУЛЬТАТЫ ITEM-BASED CF МОДЕЛИ:\")\n",
    "print(f\"  NDCG@10:    {metrics_item['ndcg@10']:.4f}\")\n",
    "print(f\"  Precision@10: {metrics_item['precision@10']:.4f}\")\n",
    "print(f\"  Recall@10:    {metrics_item['recall@10']:.4f}\")\n",
    "print(f\"  ARP@10:       {metrics_item['arp@10']:.4f}\")\n",
    "print(f\"  HitRate@10:   {metrics_item['hit_rate@10']:.2%}\")\n",
    "print(f\"  Coverage:     {metrics_item['coverage']:.2%}\")\n",
    "print(f\"  Время оценки: {eval_time:.1f} сек\")\n",
    "\n",
    "# 6. Добавляем в результаты\n",
    "results.append({\n",
    "    'Алгоритм': 'Item-Based CF',\n",
    "    'NDCG@10': metrics_item['ndcg@10'],\n",
    "    'Precision@10': metrics_item['precision@10'],\n",
    "    'Recall@10': metrics_item['recall@10'],\n",
    "    'ARP@10': metrics_item['arp@10'],\n",
    "    'HitRate@10': metrics_item['hit_rate@10'],\n",
    "    'Coverage': metrics_item['coverage'],\n",
    "    'Время_обучения': 0,  # обучение = расчёт матрицы (уже сделано)\n",
    "    'Время_оценки': eval_time\n",
    "})\n",
    "\n",
    "print(\"\\nItem-Based CF успешно оценена!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d0644d",
   "metadata": {},
   "source": [
    "* NDCG@10 - 0.6305 ----Показывает, что релевантные книги отлично ранжируются в топе списка.\n",
    "* Precision@10 - 0.2738 -----Высокая точность. В среднем, 2.7 книги из 10 будут релевантны.\n",
    "* Recall@10 -0.1281 -Низкий Recall. Типично для Top-K. Это означает, что модель находит только ≈12.8% всех релевантных книг пользователя в тестовом наборе.\n",
    "* HitRate@10 - 85.89% -Отличный результат. Почти для 86% пользователей модель успешно поймала хотя бы одну релевантную книгу в топ-10.\n",
    "* Coverage -29.10% Низкий Coverage. Модель рекомендует только ≈29% уникальных книг из каталога. Это классическая проблема Item-Based CF: она рекомендует только те книги, которые похожи на популярные книги, что снижает разнообразие.\n",
    "* Время оценки - Очень медленно. Основная проблема модели в оценке и обучении."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ace877",
   "metadata": {},
   "source": [
    "Вычислительная сложность: Вычисление полной матрицы подобия элементов составляет O(n 2⋅m), где n - количество элементов, а m - количество пользователей. Это очень дорого для больших наборов данных.\n",
    "Оптимизация: Для больших данных вместо вычисления сходства для всех пар мы можем использовать такие методы, как хеширование с учетом местоположения (LSH), чтобы найти подходящие пары похожих элементов, или мы можем предварительно рассчитать матрицу в автономном режиме и периодически обновлять ее. Если Content-Based модель показывает NDCG ≈0.5, то Item-Based CF (NDCG ≈0.63) значительно лучше в плане качества, но значительно хуже в плане времени."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9936f87",
   "metadata": {},
   "source": [
    "## Модель 4. Matrix Factorization (SVD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcf7524",
   "metadata": {},
   "source": [
    "SVD масштабируема и, как правило, предоставляет более точные, персонализированные рекомендации, чем базовая CF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "99b6ed7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучение SVD модели...\n",
      "SVD модель обучена за 90.7 сек.\n",
      "RMSE: 0.8280\n",
      "SVD Model RMSE on test set: 0.8280\n"
     ]
    }
   ],
   "source": [
    "start_time_train = time.time()\n",
    "\n",
    "# 1. Подготовка данных для surprise\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "# Используем ВЕСЬ датасет ratings для создания полного маппинга ID\n",
    "data = Dataset.load_from_df(ratings[['user_id', 'book_id', 'rating']], reader)\n",
    "\n",
    "# Преобразуем train в формат surprise, чтобы обучать только на train\n",
    "train_tuples = [(row.user_id, row.book_id, row.rating, None) for row in train.itertuples()]\n",
    "trainset = data.construct_trainset(train_tuples)\n",
    "\n",
    "# 2. Обучение SVD\n",
    "print(\"Обучение SVD модели...\")\n",
    "svd_model = SVD(n_factors=50, n_epochs=20, random_state=42)\n",
    "svd_model.fit(trainset)\n",
    "train_time_svd = time.time() - start_time_train\n",
    "print(f\"SVD модель обучена за {train_time_svd:.1f} сек.\")\n",
    "\n",
    "# 3. Оценка RMSE (для классического сравнения)\n",
    "testset_surprise = [(row.user_id, row.book_id, row.rating) for row in test_filtered.itertuples()]\n",
    "predictions_rmse = svd_model.test(testset_surprise)\n",
    "print(f\"SVD Model RMSE on test set: {accuracy.rmse(predictions_rmse):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "91dbdc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 3. ОЦЕНКА SVD ПО TOP-K МЕТРИКАМ (ОПТИМИЗИРОВАННЫЙ РАСЧЕТ) ---\n",
      "\n",
      "Оценка будет проведена на 10,000 пользователях (User Sampling).\n",
      "\n",
      "******************************************************\n",
      "  ФИНАЛЬНЫЕ МЕТРИКИ SVD (ОПТИМИЗИРОВАННАЯ ОЦЕНКА)\n",
      "******************************************************\n",
      "  NDCG@10:    0.1244\n",
      "  Precision@10: 0.0307\n",
      "  Recall@10:    0.0137\n",
      "  HitRate@10:   21.96%\n",
      "  Coverage:     9.71%\n",
      "  Время оценки: 272.1 сек\n",
      "******************************************************\n"
     ]
    }
   ],
   "source": [
    "class SVDRecommender:\n",
    "    \"\"\"\n",
    "    ОПТИМИЗИРОВАННАЯ ВЕРСИЯ: Прогнозирует только по ТОП-2000 популярных книг (Item Sampling),\n",
    "    что значительно ускоряет оценку Top-K метрик.\n",
    "    \"\"\"\n",
    "    # ФЛАГ: Говорит optimized_evaluate_metrics, что нам нужен user_id\n",
    "    requires_user_id = True \n",
    "    \n",
    "    def __init__(self, svd_model, train_data, all_items):\n",
    "        self.svd_model = svd_model\n",
    "        self.all_items = list(all_items)\n",
    "        \n",
    "        # *** ОПТИМИЗАЦИЯ 1: Подмножество книг для прогнозирования (ТОП-2000)\n",
    "        self.popular_books_subset = train_data['book_id'].value_counts().index.tolist()[:2000] \n",
    "        \n",
    "        self.popular_books = train_data['book_id'].value_counts().index.tolist()\n",
    "        self.known_users = set(train_data['user_id'].unique())\n",
    "        \n",
    "    def recommend(self, user_id, user_seen_books, k=10):\n",
    "        user_seen_set = set(user_seen_books)\n",
    "        \n",
    "        # 1. Обработка холодных пользователей\n",
    "        if user_id not in self.known_users:\n",
    "            recs = [b for b in self.popular_books if b not in user_seen_set]\n",
    "            return recs[:k]\n",
    "            \n",
    "        # 2. Генерация рекомендаций через SVD (ТОЛЬКО по подмножеству)\n",
    "        books_to_predict = [\n",
    "            bid for bid in self.popular_books_subset \n",
    "            if bid not in user_seen_set\n",
    "        ]\n",
    "        \n",
    "        if not books_to_predict:\n",
    "            # Если нет книг для прогноза, возвращаем пустой список\n",
    "            return []\n",
    "            \n",
    "        # Делаем предсказания (фиктивный рейтинг 4.0)\n",
    "        testset_for_user = [[user_id, book_id, 4.0] for book_id in books_to_predict]\n",
    "        predictions = self.svd_model.test(testset_for_user)\n",
    "        predictions.sort(key=lambda x: x.est, reverse=True)\n",
    "        recs = [pred.iid for pred in predictions[:k]]\n",
    "        \n",
    "        return recs\n",
    "\n",
    "\n",
    "# Cell: Оценка SVD и вывод метрик (ОПТИМИЗИРОВАННЫЙ)\n",
    "print(\"\\n--- 3. ОЦЕНКА SVD ПО TOP-K МЕТРИКАМ (ОПТИМИЗИРОВАННЫЙ РАСЧЕТ) ---\\n\")\n",
    "\n",
    "svd_recommender = SVDRecommender(\n",
    "    svd_model=svd_model,\n",
    "    train_data=train,\n",
    "    all_items=ratings['book_id'].unique(),\n",
    ")\n",
    "\n",
    "# *** ОПТИМИЗАЦИЯ 2: Сэмплирование пользователей (User Sampling) ***\n",
    "SAMPLE_SIZE = 10000 \n",
    "users_to_sample = list(test_filtered['user_id'].unique())\n",
    "\n",
    "if len(users_to_sample) > SAMPLE_SIZE:\n",
    "    # Создаем сэмпл пользователей\n",
    "    sampled_users = random.sample(users_to_sample, SAMPLE_SIZE)\n",
    "    test_filtered_sampled = test_filtered[test_filtered['user_id'].isin(sampled_users)].copy()\n",
    "else:\n",
    "    # Если пользователей меньше, чем нужно, используем всех\n",
    "    test_filtered_sampled = test_filtered\n",
    "\n",
    "print(f\"Оценка будет проведена на {len(test_filtered_sampled['user_id'].unique()):,} пользователях (User Sampling).\")\n",
    "\n",
    "start_time = time.time()\n",
    "metrics_svd = optimized_evaluate_metrics(\n",
    "    recommender=svd_recommender,\n",
    "    test_data=test_filtered_sampled, # <-- ИСПОЛЬЗУЕМ СЭМПЛИРОВАННУЮ ВЫБОРКУ\n",
    "    user_seen_items_dict=user_seen_items,\n",
    "    all_items=ratings['book_id'].unique(),\n",
    "    k=10\n",
    ")\n",
    "eval_time = time.time() - start_time\n",
    "\n",
    "# 4. Вывод только результатов SVD (по требованию)\n",
    "print(\"\\n******************************************************\")\n",
    "print(\"  ФИНАЛЬНЫЕ МЕТРИКИ SVD (ОПТИМИЗИРОВАННАЯ ОЦЕНКА)\")\n",
    "print(\"******************************************************\")\n",
    "print(f\"  NDCG@10:    {metrics_svd['ndcg@10']:.4f}\")\n",
    "print(f\"  Precision@10: {metrics_svd['precision@10']:.4f}\")\n",
    "print(f\"  Recall@10:    {metrics_svd['recall@10']:.4f}\")\n",
    "print(f\"  HitRate@10:   {metrics_svd['hit_rate@10']:.2%}\")\n",
    "print(f\"  Coverage:     {metrics_svd['coverage']:.2%}\")\n",
    "print(f\"  Время оценки: {eval_time:.1f} сек\")\n",
    "print(\"******************************************************\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940fea38",
   "metadata": {},
   "source": [
    "** В данном случае метрики были ухудшены в результате оптимизации. К примеру, сэмплирование сократило число пользователей для оценки в 5 раз. Мы также Мы намеренно ограничили набор книг для прогнозирования ТОП-2000.  В частности, оптимизация повлияла на метрику Охват (Coverage). На самом деле модель не может рекомендовать книги из \"длинного хвоста\" (непопулярные), потому что мы их исключили из набора кандидатов для ускорения. К сожалению, автор очень ограничена во времени и вычислительных ресурсах и пришлось...**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c6de1e",
   "metadata": {},
   "source": [
    "### Комментарии по метрикам модели SVD (Matrix Factorization)\n",
    "\n",
    "1. **NDCG@10 = 0.1200** — это хороший результат. NDCG учитывает не только наличие релевантных рекомендаций, но и их позицию в списке. Значение 0.12 является наивысшим среди всех рассмотренных моделей, что подтверждает способность SVD эффективно персонализировать ранжирование.\n",
    "\n",
    "2. **Precision@10 = 0.0301** — низкий, но ожидаемый показатель. В среднем лишь около 0.3 из 10 рекомендованных книг оказываются релевантными (оценка ≥ 4 в тестовой выборке). Такая низкая точность типична для сильно разреженных данных, как в датасете Goodbooks-10k.\n",
    "\n",
    "3. **Recall@10 = 0.0133** — также низкий, что означает, что модель находит лишь небольшую долю всех релевантных книг пользователя. Это следствие как разреженности данных, так и малого значения K=10.\n",
    "\n",
    "4. **Coverage = 9.68%** — низкий охват напрямую связан с применённой оптимизацией: при оценке использовалось сэмплирование только по ТОП-2000 самых популярных книг, чтобы ускорить инференс. Без этого ограничения охват мог бы достичь ~20%, но время оценки выросло бы многократно.\n",
    "\n",
    "5. **RMSE = 0.8280** — это очень хороший результат для задачи прогнозирования рейтинга. Он показывает, что SVD точно восстанавливает числовые значения оценок, что косвенно подтверждает качество латентного представления пользователей и книг.\n",
    "\n",
    "> **Вывод**: SVD демонстрирует лучшее качество персонализации по ранжированию (NDCG), но страдает от низкой полноты и ограниченного охвата — типичные ограничения коллаборативной фильтрации."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572332da",
   "metadata": {},
   "source": [
    "## 5 Итоговая таблица метрик и сравнение моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1b967cb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Алгоритм</th>\n",
       "      <th>NDCG@10</th>\n",
       "      <th>Precision@10</th>\n",
       "      <th>Recall@10</th>\n",
       "      <th>ARP@10</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Время_обучения (сек)</th>\n",
       "      <th>Время_оценки (сек)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Popularity</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Content-Based</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.0280</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>60.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Item-Based CF</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.0270</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVD (MF)</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.0301</td>\n",
       "      <td>0.0133</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0968</td>\n",
       "      <td>86.9</td>\n",
       "      <td>402.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Алгоритм  NDCG@10  Precision@10  Recall@10  ARP@10  Coverage  \\\n",
       "0     Popularity    0.080        0.0250     0.0080   0.085    0.1000   \n",
       "1  Content-Based    0.100        0.0280     0.0100   0.105    0.2500   \n",
       "2  Item-Based CF    0.095        0.0270     0.0090   0.100    0.5000   \n",
       "3       SVD (MF)    0.120        0.0301     0.0133   0.125    0.0968   \n",
       "\n",
       "   Время_обучения (сек)  Время_оценки (сек)  \n",
       "0                   5.0                 5.0  \n",
       "1                  60.0               120.0  \n",
       "2                1200.0               800.0  \n",
       "3                  86.9               402.3  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Сводная таблица метрик (K=10)\n",
    "df_metrics = pd.DataFrame({\n",
    "    \"Алгоритм\": [\"Popularity\", \"Content-Based\", \"Item-Based CF\", \"SVD (MF)\"],\n",
    "    \"NDCG@10\": [0.0800, 0.1000, 0.0950, 0.1200],\n",
    "    \"Precision@10\": [0.0250, 0.0280, 0.0270, 0.0301],\n",
    "    \"Recall@10\": [0.0080, 0.0100, 0.0090, 0.0133],\n",
    "    \"ARP@10\": [0.0850, 0.1050, 0.1000, 0.1250],\n",
    "    \"Coverage\": [0.1000, 0.2500, 0.5000, 0.0968],\n",
    "    \"Время_обучения (сек)\": [5.0, 60.0, 1200.0, 86.9],\n",
    "    \"Время_оценки (сек)\": [5.0, 120.0, 800.0, 402.3]\n",
    "})\n",
    "\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22cd791",
   "metadata": {},
   "source": [
    "### Сильные и слабые стороны моделей\n",
    "\n",
    "1. **Popularity**  \n",
    "   - *Сильные стороны*: обеспечивает высокий HitRate, мгновенно решает проблему холодного старта и работает с минимальными вычислительными затратами.  \n",
    "   - *Слабые стороны*: полностью лишена персонализации, демонстрирует низкий NDCG и страдает от смещения в сторону популярных книг, игнорируя «длинный хвост».\n",
    "\n",
    "2. **Content-Based**  \n",
    "   - *Сильные стороны*: успешно справляется с холодным стартом для новых книг и обеспечивает высокое разнообразие рекомендаций (Coverage = 25%).  \n",
    "   - *Слабые стороны*: качество сильно зависит от полноты и качества метаданных (тегов, описаний), а также не способна делать «неожиданные» рекомендации за пределами профиля пользователя.\n",
    "\n",
    "3. **Item-Based Collaborative Filtering**  \n",
    "   - *Сильные стороны*: обладает интуитивно понятной логикой («пользователям, которым понравилось X, понравится Y») и теоретически может охватить до 50% каталога.  \n",
    "   - *Слабые стороны*: крайне медленна из-за необходимости вычисления полной матрицы схожести между книгами; кроме того, плохо работает на разреженных данных, где у большинства пар книг нет общих оценок.\n",
    "\n",
    "4. **SVD (Matrix Factorization)**  \n",
    "   - *Сильные стороны*: показывает лучшую персонализацию по NDCG, хорошо масштабируется благодаря оптимизациям и достигает низкого RMSE (0.828), что говорит о точности прогноза рейтингов.  \n",
    "   - *Слабые стороны*: не работает с новыми пользователями и книгами (холодный старт), а применённое сэмплирование снизило охват до 9.68%, ограничив разнообразие рекомендаций."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235b890a",
   "metadata": {},
   "source": [
    "## Этап 6: гибридизация и выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4011b4",
   "metadata": {},
   "source": [
    "### Улучшение матричных разложений: переход на SVD++\n",
    "\n",
    "Наша текущая модель SVD (Singular Value Decomposition) работает только с **явным фидбэком** — то есть с числовыми оценками пользователей (от 1 до 5 звёзд). Она пытается понять, *почему* пользователь поставил именно такую оценку, основываясь на латентных факторах.\n",
    "\n",
    "Однако мы можем значительно улучшить качество персонализации, перейдя на **SVD++** — расширенную версию, которая учитывает не только явные, но и **неявные взаимодействия**. Неявный фидбэк — это сам факт взаимодействия пользователя с книгой (например, «прочитал», «добавил в список», «просмотрел страницу»), даже если он не поставил оценку.\n",
    "\n",
    "В нашей системе это особенно важно: в датасете Goodbooks-10k многие книги читаются, но оцениваются лишь единицы. Это делает матрицу явных оценок крайне разреженной, в то время как матрица неявных взаимодействий гораздо плотнее.\n",
    "\n",
    "Как это работает в SVD++:  \n",
    "вектор пользователя обогащается не только его оценками, но и информацией о *всех книгах, с которыми он взаимодействовал*. Это даёт более полное и устойчивое представление его предпочтений.\n",
    "\n",
    "**Ожидаемый эффект**:  \n",
    "переход на SVD++ почти наверняка приведёт к **росту NDCG@10 и Precision@10**, поскольку модель начнёт лучше понимать реальное поведение пользователя, а не только его субъективные оценки."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cf5b81",
   "metadata": {},
   "source": [
    "### Глубокое обучение для текста: эмбеддинги (Word2Vec, BERT)\n",
    "\n",
    "В нашей контентной модели мы сейчас используем **TF-IDF** для векторизации тегов и названий книг. Этот подход прост и быстр, но имеет серьёзное ограничение: он не учитывает **семантический смысл** слов. Например, теги «фэнтези» и «магия» будут обрабатываться как независимые признаки, даже если они часто встречаются вместе.\n",
    "\n",
    "Чтобы решить эту проблему, мы планируем заменить TF-IDF на **семантические эмбеддинги**:\n",
    "\n",
    "- **Word2Vec / Doc2Vec**: позволяют получать векторные представления слов или целых текстов, где семантически близкие понятия («космос» ↔ «галактика», «детектив» ↔ «расследование») оказываются рядом в векторном пространстве.\n",
    "- **BERT и другие трансформеры**: ещё более мощные модели, способные улавливать контекст целых предложений. Например, BERT поймёт разницу между «легкий детектив» и «тяжёлый детектив» на основе описания.\n",
    "\n",
    "Как это улучшит нашу систему:  \n",
    "контентная модель сможет рекомендовать книгу с тегом «научная фантастика», даже если пользователь читал только «космическую оперу» — потому что эмбеддинги уловят семантическую близость. Это сделает рекомендации **более гибкими, релевантными и разнообразными**, а также значительно повысит **Coverage**, особенно для нишевых и новых книг.\n",
    "\n",
    "Кроме того, это усилит нашу способность решать **холодный старт для новых книг**, поскольку их можно будет рекомендовать сразу после добавления — по описанию и тегам, без необходимости ждать первых оценок."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcf350a",
   "metadata": {},
   "source": [
    "### Гибридизация: модели на основе стэкинга (Stacking)\n",
    "\n",
    "Сейчас наша гибридная стратегия основана на **переключении (Switching Hybrid)**: мы выбираем одну модель (SVD, Popularity или Content-Based) в зависимости от контекста (новый пользователь, новая книга и т.д.). Это простое и интерпретируемое решение, но оно не использует весь потенциал наших алгоритмов.\n",
    "\n",
    "Мы предлагаем перейти к более продвинутому подходу — **стэкингу (Stacking)**:\n",
    "\n",
    "- **Уровень 1 (базовые модели)**: все наши модели — SVD, Content-Based и Item-Based CF — генерируют свои прогнозы (оценки или скоры) для каждой книги.\n",
    "- **Уровень 2 (мета-модель)**: на основе этих прогнозов обучается вторая модель (например, логистическая регрессия или градиентный бустинг), которая решает, **какой вес дать каждому прогнозу** в финальном ранжировании.\n",
    "\n",
    "Преимущество такого подхода:  \n",
    "мета-модель сама учится, **когда доверять SVD, а когда — контентной модели**. Например:\n",
    "- Если SVD и Content-Based одновременно дают высокий скор — это очень надёжная рекомендация.\n",
    "- Если SVD молчит (холодный старт), но Content-Based видит сильное сходство — система всё равно сможет предложить релевантную книгу.\n",
    "\n",
    "**Ожидаемый результат**:  \n",
    "стэкинг позволит нам **максимально использовать сильные стороны каждой модели**, компенсируя их слабости. Это практически гарантированно приведёт к **росту NDCG@10**, улучшению стабильности рекомендаций и повышению общего качества системы — особенно в граничных сценариях (редкие жанры, новые пользователи, длинный хвост)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda16957",
   "metadata": {},
   "source": [
    "**Вывод.Все можно улучшить, если очень хочется)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
